{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acerca del conjunto de datos\n",
    "\n",
    "Cienmil imagenes generadas de forma aleatoria con entre 5 y 15 piezas.\n",
    "\n",
    "Las imágenes fueron generadas usando 28 estilos de tableros de ajedrez y 32 estilos de piezas diferentes generando 896 combinaciones de estilo. \n",
    "\n",
    "Fueron generadas con este [generador de tableros digitales](https://github.com/koryakinp/chess-generator)\n",
    "\n",
    "Las imagenes son originalmente de 400 x 400 pixeles. \n",
    "\n",
    "El conjunto de entrenamiento tiene 80000 imagenes y pruebas 20000 imagenes. \n",
    "\n",
    "La distribución de probabilidad es \n",
    "\n",
    "30% peón\n",
    "20% alfil\n",
    "20% Rey\n",
    "20% Torre\n",
    "10% Reina\n",
    "\n",
    "El nombre del archivo fue etiquetado conforme a la notación Forsyth–Edwards Notation (FEN) que es una representación posicional de las piezas en el tablero:\n",
    "\n",
    "![alt text](FEN_all_string.png)\n",
    "\n",
    "![alt text](fen_one_rank.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import layers, models, optimizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.initializers import he_normal, lecun_normal\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from math import ceil\n",
    "from skimage import io, transform\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de variables para entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # Número de muestras procesadas en un lote durante el entrenamiento.\n",
    "Epoch = 100 # Número de veces que el algoritmo trabajará a través de todo el conjunto de datos.\n",
    "k_folds = 5 # Número de particiones para la validación cruzada.\n",
    "PATIENCE = 5 # Número de épocas sin mejora después de las cuales el entrenamiento se detendrá.\n",
    "SEED = 666 # Semilla para la generación de números aleatorios para reproducibilidad.\n",
    "SQUARE_SIZE = 40 # Tamaño del lado del cuadrado, debe ser menor que 400/8=50.\n",
    "test_size = 500 # Número de muestras en el conjunto de prueba.\n",
    "train_size = 3000 # Número de muestras en el conjunto de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización de las semillas en numpy y tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "from numpy.random import seed\n",
    "seed(SEED)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTA_DATOS = './data'\n",
    "RUTA_IMAGENES_ENTRENAMIENTO = os.path.join(RUTA_DATOS, 'train')\n",
    "RUTA_IMAGENES_PRUEBA = os.path.join(RUTA_DATOS, 'test')\n",
    "def get_image_filenames(image_path, image_type):\n",
    "    \"\"\"\n",
    "    Obtiene una lista de nombres de archivos de imágenes de un tipo específico en un directorio dado.\n",
    "\n",
    "    Parámetros:\n",
    "    - image_path (str): La ruta al directorio donde se encuentran las imágenes.\n",
    "    - image_type (str): El tipo de archivo de las imágenes a buscar (ej. 'jpg', 'png').\n",
    "\n",
    "    Retorna:\n",
    "    - list: Una lista de rutas completas a los archivos que coinciden con el tipo de imagen especificado.\n",
    "      Si el directorio no existe, devuelve None.\n",
    "\n",
    "    Ejemplo:\n",
    "    - get_image_filenames('/ruta/a/imagenes', 'jpg') -> Devuelve todas las rutas de archivos .jpg en el directorio especificado.\n",
    "    \"\"\"\n",
    "    if(os.path.exists(image_path)):\n",
    "        return glob.glob(os.path.join(image_path, '*.' + image_type))\n",
    "    return None  # Explícitamente devuelve None si el directorio no existe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = get_image_filenames(RUTA_IMAGENES_ENTRENAMIENTO, \"jpeg\")\n",
    "test = get_image_filenames(RUTA_IMAGENES_PRUEBA, \"jpeg\")\n",
    "\n",
    "random.shuffle(datos)\n",
    "random.shuffle(test)\n",
    "\n",
    "datos = datos[:train_size]\n",
    "test = test[:test_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mostramos 10 como ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data\\\\train\\\\3Rk3-6p1-5p2-3pp1p1-1K6-8-R3b3-4B3.jpeg',\n",
       " './data\\\\train\\\\7N-5PK1-1n1b2b1-1p4k1-8-2n1p3-4N3-2b5.jpeg',\n",
       " './data\\\\train\\\\6r1-3P4-8-1K1pk2p-2r5-6r1-3p4-3q4.jpeg',\n",
       " './data\\\\train\\\\1b6-1K6-p7-8-Q3k2P-1R6-3B4-4nnq1.jpeg',\n",
       " './data\\\\train\\\\7Q-2RK1P2-1b6-5Pp1-2pr4-8-3k1RN1-bn2r3.jpeg',\n",
       " './data\\\\train\\\\1Kn4R-2p5-1N6-4pP2-1q2N3-8-5k2-5bN1.jpeg',\n",
       " './data\\\\train\\\\1K6-1R3rQ1-6k1-N7-1p4B1-r4p2-8-8.jpeg',\n",
       " './data\\\\train\\\\8-8-8-3K2kP-5bR1-8-1p1R1N2-1B6.jpeg',\n",
       " './data\\\\train\\\\6k1-8-5r2-b3p1B1-K7-4b3-7r-2Q2bBb.jpeg',\n",
       " './data\\\\train\\\\1b2b1kQ-8-8-1p2R3-2KR4-3bp3-2nN4-4r3.jpeg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3Rk3-6p1-5p2-3pp1p1-1K6-8-R3b3-4B3\n"
     ]
    }
   ],
   "source": [
    "def fen_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extrae el nombre base de un archivo sin su extensión desde una ruta de archivo completa.\n",
    "\n",
    "    Parámetros:\n",
    "    - filename (str): La ruta completa del archivo del cual se desea extraer el nombre base.\n",
    "\n",
    "    Retorna:\n",
    "    - str: El nombre del archivo sin la extensión.\n",
    "\n",
    "    Ejemplo:\n",
    "    - fen_from_filename('/ruta/al/archivo/ejemplo.txt') -> 'ejemplo'\n",
    "    \"\"\"\n",
    "    base = os.path.basename(filename)  # Extrae el nombre del archivo con extensión desde la ruta completa.\n",
    "    return os.path.splitext(base)[0]    # Elimina la extensión del nombre del archivo y devuelve el resultado.\n",
    "print(fen_from_filename(datos[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para mostrar un rango de imágenes de un conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muestra_rango_de_imagenes(datos, rango):\n",
    "    \"\"\"\n",
    "    Muestra las primeras tres imágenes de una lista de rutas de archivos de imagen, \n",
    "    junto con sus nombres de archivo (sin extensiones) como títulos.\n",
    "\n",
    "    Parámetros:\n",
    "    - train (list): Lista de rutas completas a las imágenes a mostrar.\n",
    "    - rango (range): ejemplo range(0, 3)\n",
    "\n",
    "    Ejemplo:\n",
    "    - mostrar_imagenes(['/ruta/a/imagen1.jpg', '/ruta/a/imagen2.jpg', '/ruta/a/imagen3.jpg'])\n",
    "    \"\"\"\n",
    "    f, axarr = plt.subplots(1, 3, figsize=(120, 120))  # Configura un subplot con 3 ejes.\n",
    "\n",
    "    for i in rango:\n",
    "        base = os.path.basename(datos[i])             # Extrae el nombre del archivo con extensión.\n",
    "        nombre_sin_extension = os.path.splitext(base)[0]  # Elimina la extensión del nombre del archivo.\n",
    "        axarr[i].set_title(nombre_sin_extension, fontsize=70, pad=30)  # Establece el título del eje.\n",
    "        axarr[i].imshow(mpimg.imread(datos[i]))       # Carga y muestra la imagen.\n",
    "        axarr[i].axis('off')                          # Desactiva los ejes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De manera informativa, mostrar 3 imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m muestra_rango_de_imagenes(\u001b[43mtrain\u001b[49m, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "muestra_rango_de_imagenes(train, range(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para tratar las cadenas FEN como one-hot y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def onehot_from_fen(fen):\n",
    "    \"\"\"\n",
    "    Convierte una cadena FEN en una matriz one-hot que representa el estado del tablero de ajedrez.\n",
    "\n",
    "    Parámetros:\n",
    "    - fen (str): Cadena FEN que describe la disposición de las piezas en un tablero de ajedrez.\n",
    "\n",
    "    Retorna:\n",
    "    - np.ndarray: Una matriz one-hot donde cada fila representa una pieza en el tablero y cada columna\n",
    "                  representa un tipo de pieza o un espacio vacío.\n",
    "\n",
    "    Detalles:\n",
    "    - '12345678' se utilizan para representar el número de espacios vacíos consecutivos.\n",
    "    - 'piece_symbols' debe ser una lista previamente definida con los símbolos de las piezas correspondientes.\n",
    "    \"\"\"\n",
    "    piece_symbols = 'prbnkqPRBNKQ'\n",
    "    eye = np.eye(13)  # Crea una matriz identidad para representar las piezas y espacios vacíos.\n",
    "    output = np.empty((0, 13))  # Inicializa la matriz de salida.\n",
    "    fen = re.sub('[-]', '', fen)  # Elimina guiones, que no son necesarios en la representación.\n",
    "\n",
    "    for char in fen:\n",
    "        if char in '12345678':\n",
    "            output = np.append(output, np.tile(eye[12], (int(char), 1)), axis=0)  # Espacios vacíos.\n",
    "        else:\n",
    "            idx = piece_symbols.index(char)  # Encuentra el índice de la pieza en la lista.\n",
    "            output = np.append(output, eye[idx].reshape((1, 13)), axis=0)  # Añade la pieza a la matriz.\n",
    "\n",
    "    return output\n",
    "\n",
    "def fen_from_onehot(one_hot):\n",
    "    \"\"\"\n",
    "    Convierte una matriz one-hot en una cadena FEN que representa el estado del tablero de ajedrez.\n",
    "\n",
    "    Parámetros:\n",
    "    - one_hot (np.ndarray): Matriz one-hot donde cada fila representa una pieza en el tablero y cada columna\n",
    "                            representa un tipo de pieza o un espacio vacío.\n",
    "\n",
    "    Retorna:\n",
    "    - str: Una cadena FEN que describe la disposición de las piezas en un tablero de ajedrez.\n",
    "\n",
    "    Detalles:\n",
    "    - 'piece_symbols' debe ser una lista previamente definida con los símbolos de las piezas correspondientes.\n",
    "    \"\"\"\n",
    "    piece_symbols = 'prbnkqPRBNKQ'\n",
    "    output = ''\n",
    "    for j in range(8):\n",
    "        for i in range(8):\n",
    "            if one_hot[j][i] == 12:\n",
    "                output += ' '  # Representa un espacio vacío.\n",
    "            else:\n",
    "                output += piece_symbols[one_hot[j][i]]  # Añade el símbolo de la pieza.\n",
    "        if j != 7:\n",
    "            output += '-'  # Añade un guión entre las filas.\n",
    "\n",
    "    for i in range(8, 0, -1):\n",
    "        output = output.replace(' ' * i, str(i))  # Compacta espacios vacíos en números.\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de onehot from fen limitado a 10 filas\n",
    "onehot_from_fen('1r6-8-8-5Q2-1K4r1-6P1-Pb6-3k4')[0:8]\n",
    "# Recordar que el orden es: prbnkqPRBNKQ\n",
    "# La primera fila dice 1 vacia, luego rook, luego 6 vacias. \n",
    "# Esto está representado en one-hot de la siguiente manera\n",
    "# Primera fila, la ultima columna representa casilla vacía y está en 1\n",
    "# La fila 2, la columna 2, es la rook negra y está en 1\n",
    "# Luego 6 filas que también representan casilla vacía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para procesar imágenes de tableros de ajedrez, que regresa los 64 cuadros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "from skimage.util import view_as_blocks\n",
    "\n",
    "def process_image(img):\n",
    "    \"\"\"\n",
    "    Procesa una imagen reduciéndola a un tamaño especificado y dividiéndola en cuadrados más pequeños.\n",
    "\n",
    "    Parámetros:\n",
    "    - img (str): Ruta al archivo de imagen que se va a procesar.\n",
    "\n",
    "    Retorna:\n",
    "    - np.ndarray: Un arreglo numpy que contiene 64 tiles (cuadrados) de la imagen, cada uno con\n",
    "                  dimensiones (SQUARE_SIZE, SQUARE_SIZE, 3), donde 3 representa los canales de color RGB.\n",
    "\n",
    "    Detalles:\n",
    "    - 'SQUARE_SIZE' debe ser definida externamente y representa el tamaño de cada cuadrado en el que se divide la imagen.\n",
    "    - La imagen es redimensionada a un tamaño de (SQUARE_SIZE*8, SQUARE_SIZE*8) antes de ser dividida.\n",
    "    - Esta función es útil para preparar imágenes para su análisis o procesamiento en tareas que requieren\n",
    "      datos en forma de cuadrícula o matriz, como el análisis de tableros de juegos.\n",
    "    \"\"\"\n",
    "    new_image_size = SQUARE_SIZE * 8  # Calcula el nuevo tamaño deseado de la imagen.\n",
    "    square_size = SQUARE_SIZE  # Tamaño de cada cuadrado en el que se dividirá la imagen.\n",
    "    img_read = io.imread(img)  # Lee la imagen desde la ruta especificada.\n",
    "    # Redimensiona la imagen al tamaño deseado.\n",
    "    img_read = transform.resize(img_read, (new_image_size, new_image_size), mode='constant')\n",
    "    # Divide la imagen en bloques más pequeños de tamaño (square_size, square_size, 3).\n",
    "    tiles = view_as_blocks(img_read, block_shape=(square_size, square_size, 3))\n",
    "    # Elimina una dimensión redundante que podría haber sido creada durante el proceso de división.\n",
    "    tiles = tiles.squeeze(axis=2)\n",
    "    # Reorganiza las baldosas para que estén en una sola dimensión con las dimensiones requeridas por tile.\n",
    "    return tiles.reshape(64, square_size, square_size, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función train_gen\n",
    "Esta función es un generador que produce lotes de datos de entrenamiento a partir de un conjunto de características, utilizando una codificación one-hot y procesamiento de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(features_paths, batch_size):\n",
    "    \"\"\"\n",
    "    Genera lotes de datos de entrenamiento a partir de un conjunto de rutas de imágenes.\n",
    "    Etiquetandolas con la codificación one-hot\n",
    "\n",
    "    Parámetros:\n",
    "    - features_paths (list): Lista de rutas de imágenes.\n",
    "    - batch_size (int): Tamaño del lote de imágenes a procesar.\n",
    "\n",
    "    Yields:\n",
    "    - tuple: Tupla que contiene dos arrays numpy, uno para las imágenes procesadas (X) y otro para las etiquetas (Y),\n",
    "             cada uno codificado como one-hot.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while True:\n",
    "        batch_x, batch_y = [], []\n",
    "        for _ in range(batch_size):\n",
    "            if i == len(features_paths):\n",
    "                i = 0\n",
    "                random.shuffle(features_paths)\n",
    "            img = str(features_paths[i])\n",
    "            y = onehot_from_fen(fen_from_filename(img))\n",
    "            x = process_image(img)\n",
    "            batch_x.extend(x)\n",
    "            batch_y.extend(y)\n",
    "            i += 1\n",
    "        yield (np.array(batch_x), np.array(batch_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función pred gen\n",
    "Esta función es un generador que produce datos procesados de imágenes para predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_gen(features_paths, batch_size):\n",
    "    \"\"\"\n",
    "    Genera lotes de imágenes procesadas para predicción.\n",
    "\n",
    "    Parámetros:\n",
    "    - features_paths (list): Lista de rutas de imágenes.\n",
    "    - batch_size (int): Tamaño del lote de imágenes a procesar.\n",
    "\n",
    "    Yields:\n",
    "    - np.ndarray: Array de imágenes procesadas.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(features_paths):\n",
    "        batch_images = [process_image(features_paths[j]) for j in range(i, min(i + batch_size, len(features_paths)))]\n",
    "        i += batch_size\n",
    "        yield np.array(batch_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de callbacks documentada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name, patient):\n",
    "    \"\"\"\n",
    "    Configura y retorna una lista de callbacks útiles para el entrenamiento de modelos en Keras.\n",
    "\n",
    "    Parámetros:\n",
    "    - model_name (str): Ruta y nombre del archivo donde se guardará el modelo con mejor rendimiento.\n",
    "    - patient (int): Número de épocas sin mejora en la pérdida de validación después de las cuales se tomarán medidas.\n",
    "\n",
    "    Retorna:\n",
    "    - list: Lista de objetos callback configurados para ser usados durante el entrenamiento.\n",
    "\n",
    "    Callbacks configurados:\n",
    "    - EarlyStopping: Detiene el entrenamiento cuando una métrica monitoreada ha dejado de mejorar.\n",
    "      * monitor='val_loss': La métrica a monitorear, en este caso, la pérdida de validación.\n",
    "      * patience=patient: El número de épocas para esperar después de una mejora antes de detener el entrenamiento.\n",
    "      * mode='min': Establece que la métrica monitoreada debe minimizarse (pérdida de validación menor es mejor).\n",
    "      * verbose=1: Habilita la salida detallada de mensajes (1) para visualizar el progreso en la consola.\n",
    "\n",
    "    - ReduceLROnPlateau: Reduce la tasa de aprendizaje cuando una métrica de rendimiento se ha estancado.\n",
    "      * monitor='val_loss': La métrica a monitorear.\n",
    "      * factor=0.5: Factor por el cual se reducirá la tasa de aprendizaje.\n",
    "      * patience=patient / 2: Número de épocas para esperar antes de reducir la tasa de aprendizaje.\n",
    "      * min_lr=0.000001: El límite inferior de la tasa de aprendizaje.\n",
    "      * verbose=1: Habilita mensajes detallados.\n",
    "      * mode='min': Busca minimizar la métrica monitoreada.\n",
    "\n",
    "    - ModelCheckpoint: Guarda el modelo después de cada época solo si es el mejor encontrado hasta el momento en términos de pérdida de validación.\n",
    "      * filepath=model_name: Ruta donde se guardará el modelo.\n",
    "      * monitor='val_loss': Métrica para determinar el mejor modelo.\n",
    "      * verbose=1: Habilita mensajes detallados.\n",
    "      * save_best_only=True: Guarda solo el modelo que tiene la mejor métrica de 'val_loss'.\n",
    "      * mode='min': Busca minimizar la métrica monitoreada.\n",
    "\n",
    "    Ejemplo de uso:\n",
    "    callbacks = get_callbacks('modelo_mejor.h5', 10)\n",
    "    model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=callbacks)\n",
    "    \"\"\"\n",
    "    # Configuración de EarlyStopping\n",
    "    ES = EarlyStopping(monitor='val_loss', patience=patient, mode='min', verbose=1)\n",
    "    # Configuración de ReduceLROnPlateau\n",
    "    RR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=int(patient / 2), min_lr=0.000001, verbose=1, mode='min')\n",
    "    # Configuración de ModelCheckpoint\n",
    "    MC = ModelCheckpoint(filepath=model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "    return [ES, RR, MC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcionamiento de la Pérdida por Entropía Cruzada Categórica Ponderada\n",
    "La entropía cruzada categórica es una medida comúnmente utilizada para evaluar el error entre las probabilidades predichas y las etiquetas verdaderas en problemas de clasificación. La versión ponderada modifica esta medida para dar más o menos importancia a ciertas clases durante el entrenamiento del modelo:\n",
    "\n",
    "- Normalización y Escalado: Las predicciones (y_pred) se normalizan para asegurar que las probabilidades de cada muestra sumen 1, ajustándolas según los pesos de cada clase.\n",
    "- Estabilidad Numérica: Se utiliza K.clip para evitar valores de logaritmo de cero, que resultarían en NaN o Inf, lo cual podría desestabilizar el entrenamiento del modelo.\n",
    "- Aplicación de Pesos: Los pesos se aplican directamente en el cálculo del logaritmo de las predicciones, lo cual ajusta el impacto de las predicciones incorrectas según la importancia de cada clase. Así, los errores en clases con mayor peso tienen un impacto proporcionalmente mayor en la función de pérdida.\n",
    "\n",
    "Esta funcionalidad es especialmente útil en datasets desbalanceados, donde algunas clases son menos frecuentes pero más críticas. Al ajustar los pesos, se puede guiar al modelo para que preste más atención a estas clases menos representadas pero importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    Devuelve una función de pérdida de entropía cruzada categórica ponderada personalizada para usar en entrenamientos de modelos de Keras.\n",
    "\n",
    "    Parámetros:\n",
    "    - weights (np.array): Un arreglo de numpy con forma (C,) donde C es el número de clases. \n",
    "                          Cada elemento del arreglo asigna un peso a la correspondiente clase para calcular la pérdida.\n",
    "\n",
    "    Uso:\n",
    "    - weights = np.array([0.5, 2, 10]) # Clase 1 con peso 0.5, clase 2 con el doble del peso normal, clase 3 con 10 veces el peso.\n",
    "    - loss = weighted_categorical_crossentropy(weights)\n",
    "    - model.compile(loss=loss, optimizer='adam')\n",
    "\n",
    "    Retorna:\n",
    "    - loss (function): Una función que calcula la entropía cruzada categórica ponderada entre `y_true` y `y_pred`.\n",
    "\n",
    "    Ejemplo de uso:\n",
    "    model.compile(loss=weighted_categorical_crossentropy(np.array([1, 2, 0.5])), optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)  # Convierte los pesos a una variable de Keras para su uso en cálculos de tensor.\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # Escala las predicciones para que la suma de probabilidades de cada muestra sea 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # Limita los valores predichos para evitar NaN's e Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # Calcula la pérdida usando los pesos asignados a cada clase\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del modelo\n",
    "\n",
    "## Descripción del Modelo de Red Neuronal Convolucional\n",
    "\n",
    "### Arquitectura del Modelo\n",
    "\n",
    "La arquitectura del modelo está diseñada para procesar imágenes mediante una serie de capas que extraen características y aplican regularización para mejorar la generalización:\n",
    "\n",
    "1. **Capas Conv2D**: \n",
    "   - Tres capas convolucionales con 32 filtros de tamaño 3x3 y activación ReLU. Estas capas extraen características visuales básicas como bordes y texturas.\n",
    "\n",
    "2. **Capas de Dropout**: \n",
    "   - Capas que aplican un dropout del 20% después de cada capa convolucional para reducir el riesgo de sobreajuste, ayudando al modelo a generalizar mejor a nuevos datos.\n",
    "\n",
    "3. **Capa MaxPooling2D**: \n",
    "   - Una capa de agrupación máxima con un tamaño de 2x2 que reduce la dimensionalidad de las características, conservando las características más prominentes.\n",
    "\n",
    "4. **Capa Flatten**: \n",
    "   - Esta capa aplana las características multidimensionales en un vector unidimensional, preparándolas para el procesamiento en capas densas.\n",
    "\n",
    "5. **Capas Dense**: \n",
    "   - Una capa densa de 128 neuronas con activación ReLU seguida de una capa de salida con 13 neuronas y activación softmax, que clasifica las imágenes en una de las 13 categorías basadas en las características extraídas.\n",
    "\n",
    "### Compilación del Modelo\n",
    "\n",
    "- El modelo utiliza la entropía cruzada categórica ponderada como función de pérdida, con un ajuste dinámico de la tasa de aprendizaje y la métrica de precisión para evaluar el rendimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import models, layers\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "class ChessFENClassifier:\n",
    "    \"\"\"\n",
    "    Clasificador de imágenes de ajedrez para convertir imágenes cuadradas en cadenas FEN utilizando una red neuronal convolucional.\n",
    "\n",
    "    Atributos:\n",
    "    - image_size (int): Tamaño de las imágenes (ancho y alto) que acepta el modelo.\n",
    "\n",
    "    Métodos:\n",
    "    - __init__(self, image_size): Constructor de la clase que inicializa el tamaño de la imagen.\n",
    "    - build_model(self): Construye y compila el modelo de red neuronal.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_size):\n",
    "        \"\"\"\n",
    "        Inicializa el clasificador con el tamaño especificado de las imágenes.\n",
    "\n",
    "        Parámetros:\n",
    "        - image_size (int): Tamaño de las imágenes cuadradas.\n",
    "        \"\"\"\n",
    "        self.image_size = image_size\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Construye y compila el modelo de red neuronal utilizando la arquitectura CNN con Keras.\n",
    "\n",
    "        Retorna:\n",
    "        - model (keras.Model): Modelo de red neuronal convolucional compilado.\n",
    "        \"\"\"\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', input_shape=(self.image_size, self.image_size, 3)))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Dense(13, activation='softmax', kernel_initializer='lecun_normal'))\n",
    "\n",
    "        # Cálculo de los pesos para la pérdida por entropía cruzada categórica ponderada\n",
    "        # 30% peón 20% alfil 20% Rey 20% Torre 10% Reina\n",
    "        weights = np.array([1/(0.30*4), 1/(0.20*4), 1/(0.20*4), 1/(0.20*4), 1/1, 1/(0.10*4),\n",
    "                            1/(0.30*4), 1/(0.20*4), 1/(0.20*4), 1/(0.20*4), 1/1, 1/(0.10*4), 1/(64-10)])\n",
    "        model.compile(loss=weighted_categorical_crossentropy(weights), optimizer=Nadam(), metrics=['accuracy'])\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChessFENClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mChessFENClassifier\u001b[49m(SQUARE_SIZE)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m      3\u001b[0m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ChessFENClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = ChessFENClassifier(SQUARE_SIZE)\n",
    "model = classifier.model\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
